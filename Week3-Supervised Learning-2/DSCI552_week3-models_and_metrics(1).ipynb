{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DSCI 552 Machine Learning For Data Science\n",
    "    \n",
    "## Small Examples\n",
    "\n",
    "**Week 03 | Lecture 05**\n",
    "\n",
    "_Tuesday, February 2, 2020_\n",
    "\n",
    "Presented by Dr. Keith Burghardt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#import numpy\n",
    "import numpy as np\n",
    "import pandas\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]).reshape(-1, 1)\n",
    "y1 = [1,1,1,0,0,0,0,0,1,1,1]#8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\n",
    "y2 = [0,0,0,0,0,0,1,1,1,1,1]#[9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\n",
    "y3 = [1,1,0,1,0,0,1,0,1,0,1]#[7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\n",
    "x4 = [0,0,0,0,0,0,0,0,0,0,1]#[8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\n",
    "\n",
    "x4 = np.array([8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]).reshape(-1, 1)\n",
    "y4 = [0,1,0,1,0,0,1,1,0,1,1]#[6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e14054c5813e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'go'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_x' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAD8CAYAAABuKoLZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAV/0lEQVR4nO3df4xlZ3kf8O+DN2675Ac0XmjiH6xbGRwH4RQGTFqlcUIpa5LiRiKSjRsoJVpZAYoqVbVRFFIJoTaiUWhkwFkR10FdYVWEhg1yICgV4Q9E5N0EDDY1XRmwF9N4HWj+wFLdhad/3Lv0enx25+z6zr1z73w+0mrmnPvunOfdmXvmu+8573mruwMAADzZM5ZdAAAA7ESCMgAADBCUAQBggKAMAAADBGUAABggKAMAwABBGWDNVNUdVfVoVX3xDK9XVf12VR2vqnur6sWLrhFgFQjKAOvnziQHzvL6dUmumP45mOT9C6gJYOUIygBrprs/neSbZ2lyfZIP9sRnkzyrqn5kMdUBrI49yzrwRRdd1Pv371/W4QGelmPHjj3W3fuWXcd5ujjJwzPbJ6b7vjHbqKoOZjLinGc+85kvufLKKxdWIMA8ne85e2lBef/+/Tl69OiyDg/wtFTV15Zdw9NQA/v6KTu6DyU5lCQbGxvtnA2sqvM9Z7v1AmD3OZHk0pntS5I8sqRaAHYsQRlg9zmS5PXTp1+8PMlfd/c3tvpLALvN0m69AGB7VNWHklyb5KKqOpHk15N8X5J09+1J7k7y6iTHkzye5I3LqRRgZxOUAdZMd9+4xeud5M0LKgdgZbn1AgAABmwZlHfKCk+HDyf79yfPeMbk4+HD23GU5Rxv0X2DMdb5PbeM4wGwesbcenFnktuSfPAMr8+u8HRNJis8XTOP4k47fDg5eDB5/PHJ9te+NtlOkptumueRFn+8RfcNxljn99wyjgfAaqrJrWpbNKran+Rj3f3Cgdd+J8mnuvtD0+0Hkly71Qzqc3km5/79k19kmz3veclXvzrqS5yTRR5v0X2DMdb5PTev41XVse7emGddO5nnKAOr7HzP2fO4R/lMKzw9RVUdrKqjVXX05MmTow/w0EPntv/pWuTxFt03GGOd33PLOB4Aq2keQXnUCk/JZJWn7t7o7o19+8avInjZZee2/+la5PEW3TcYY53fc8s4HgCraR5BedtXeHrXu5K9e5+8b+/eyf7tsMjjLbpvMMY6v+eWcTwAVtM8gvK2r/B0003JoUOT+werJh8PHdq+STeLPN6i+wZjrPN7bhnHA2A1bTmZb3aFpyR/mU0rPFVVZfJUjAOZrvDU3VvO+DAxBFhlJvMBrI7zPWdv+Xg4KzwBALAbWZkPAAAGCMoAADBAUAYAgAGCMgAADBCUAQBggKAMAAADBGUAABggKAMAwABBGQAABgjKAAAwQFAGAIABgjIAAAwQlAEAYICgDAAAAwRlAAAYICgDAMAAQRkAAAYIygAAMEBQBgCAAYIyAAAMEJQBAGCAoAwAAAMEZQAAGCAoAwDAAEEZAAAGCMoAa6aqDlTVA1V1vKpuHXj9h6rqD6vq81V1X1W9cRl1Aux0gjLAGqmqC5K8N8l1Sa5KcmNVXbWp2ZuT3N/dVye5NslvVtWFCy0UYAUIygDr5WVJjnf3g939RJK7kly/qU0n+YGqqiTfn+SbSU4ttkyAnU9QBlgvFyd5eGb7xHTfrNuS/FiSR5J8Icnbuvu7m79QVR2sqqNVdfTkyZPbVS/AjiUoA6yXGtjXm7ZfleRzSX40yU8kua2qfvApf6n7UHdvdPfGvn375l8pwA4nKAOslxNJLp3ZviSTkeNZb0zykZ44nuQrSa5cUH0AK2NUUDaDGmBl3JPkiqq6fDpB74YkRza1eSjJK5Kkqp6b5AVJHlxolQArYM9WDWZmUL8yk5GKe6rqSHffP9Ps9Azqf1pV+5I8UFWHpxNJAFiQ7j5VVW9J8okkFyS5o7vvq6qbp6/fnuSdSe6sqi9kcqvGLd392NKKBtihtgzKmZlBnSRVdXoG9WxQNoMaYIfo7ruT3L1p3+0znz+S5J8sui6AVTPm1gszqAEA2HXGBGUzqAEA2HXGBGUzqAEA2HXGBGUzqAEA2HW2nMxnBjUAALvRmKdemEENAMCuY2U+AAAYICgDAMAAQRkAAAYIygAAMEBQBgCAAYIyAAAMEJQBAGCAoAwAAAMEZQAAGCAoAwDAAEEZAAAGCMoAADBAUAYAgAGCMgAADBCUAQBggKAMAAADBGUAABggKAMAwABBGQAABgjKAAAwQFAGAIABgjIAAAwQlAEAYICgDAAAAwRlAAAYICgDAMAAQRkAAAYIygAAMEBQBlgzVXWgqh6oquNVdesZ2lxbVZ+rqvuq6k8XXSPAKtiz7AIAmJ+quiDJe5O8MsmJJPdU1ZHuvn+mzbOSvC/Jge5+qKqes5xqAXa2USPKRicAVsbLkhzv7ge7+4kkdyW5flOb1yX5SHc/lCTd/eiCawRYCVsG5ZnRieuSXJXkxqq6alOb06MTr+nuH0/yi9tQKwBbuzjJwzPbJ6b7Zj0/ybOr6lNVdayqXj/0harqYFUdraqjJ0+e3KZyAXauMSPKRicAVkcN7OtN23uSvCTJzyV5VZJfq6rnP+UvdR/q7o3u3ti3b9/8KwXY4cYEZaMTAKvjRJJLZ7YvSfLIQJuPd/e3u/uxJJ9OcvWC6gNYGWOCstEJgNVxT5IrquryqrowyQ1Jjmxq89EkP1VVe6pqb5JrknxpwXUC7HhjnnoxdnTise7+dpJvV9Xp0Ykvz6VKAEbp7lNV9ZYkn0hyQZI7uvu+qrp5+vrt3f2lqvp4knuTfDfJB7r7i8urGmBnGhOUvzc6keTrmYxOvG5Tm48mua2q9iS5MJPRid+aZ6EAjNPddye5e9O+2zdtvzvJuxdZF8Cq2TIoG50AAGA3GrXgiNEJAAB2G0tYAwDAAEEZAAAGCMoAADBAUAYAgAGCMgAADBCUAQBggKAMAAADBGUAABggKAMAwABBGQAABgjKAAAwQFAGAIABgjIAAAwQlAEAYICgDAAAAwRlAAAYICgDAMAAQRkAAAYIygAAMEBQBgCAAYIyAAAMEJQBAGCAoAwAAAMEZQAAGCAoAwDAAEEZAAAGCMoAADBAUAYAgAGCMgAADBCUAQBggKAMAAADRgXlqjpQVQ9U1fGquvUs7V5aVd+pqtfOr0QAAFi8LYNyVV2Q5L1JrktyVZIbq+qqM7T7jSSfmHeRAACwaGNGlF+W5Hh3P9jdTyS5K8n1A+3emuT3kzw6x/oAOEeuAgLMx5igfHGSh2e2T0z3fU9VXZzkF5LcfrYvVFUHq+poVR09efLkudYKwBZcBQSYnzFBuQb29abt9yS5pbu/c7Yv1N2Hunujuzf27ds3tkYAxnMVEGBO9oxocyLJpTPblyR5ZFObjSR3VVWSXJTk1VV1qrv/YC5VAjDW0FXAa2YbzFwF/NkkLz3TF6qqg0kOJslll10290IBdroxI8r3JLmiqi6vqguT3JDkyGyD7r68u/d39/4kH07yK0IywFK4CggwJ1uOKHf3qap6Syb3sV2Q5I7uvq+qbp6+ftb7kgFYKFcBAeZkzK0X6e67k9y9ad9gQO7uf/H0ywLgPH3vKmCSr2dyFfB1sw26+/LTn1fVnUk+JiQDPNWooAzAanAVEGB+BGWANeMqIMB8jFrCGgAAdhtBGQAABgjKAAAwQFAGAIABgjIAAAwQlAEAYICgDAAAAwRlAAAYICgDAMAAQRkAAAYIygAAMEBQBgCAAYIyAAAMEJQBAGCAoAwAAAMEZQAAGCAoAwDAAEEZAAAGCMoAADBAUAYAgAGCMgAADBCUAQBggKAMAAADBGUAABggKAMAwABBGQAABgjKAAAwQFAGAIABo4JyVR2oqgeq6nhV3Trw+k1Vde/0z2eq6ur5lwoAAIuzZVCuqguSvDfJdUmuSnJjVV21qdlXkvx0d78oyTuTHJp3oQAAsEhjRpRfluR4dz/Y3U8kuSvJ9bMNuvsz3f2t6eZnk1wy3zIBAGCxxgTli5M8PLN9YrrvTN6U5I+GXqiqg1V1tKqOnjx5cnyVAACwYGOCcg3s68GGVT+TSVC+Zej17j7U3RvdvbFv377xVQIAwILtGdHmRJJLZ7YvSfLI5kZV9aIkH0hyXXf/1XzKAwCA5RgzonxPkiuq6vKqujDJDUmOzDaoqsuSfCTJL3X3l+dfJgBjeVIRwHxsOaLc3aeq6i1JPpHkgiR3dPd9VXXz9PXbk7wjyQ8neV9VJcmp7t7YvrIBGDLzpKJXZnJF8J6qOtLd9880O/2kom9V1XWZPKnomsVXC7Czjbn1It19d5K7N+27febzX07yy/MtDYDz8L0nFSVJVZ1+UtH3gnJ3f2amvScVAZyBlfkA1osnFQHMiaAMsF48qQhgTkbdegHAyvCkIoA5MaIMsF48qQhgTowoA6wRTyoCmB9BGWDNeFIRwHy49QIAAAYIygAAMEBQBgCAAYIyAAAMEJQBAGCAoAwAAAMEZQAAGCAoAwDAAEEZAAAGCMoAADBAUAYAgAGCMgAADBCUAQBggKAMAAADBGUAABggKAMAwABBGQAABgjKAAAwQFAGAIABgjIAAAwQlAEAYICgDAAAAwRlAAAYICgDAMAAQRkAAAaMCspVdaCqHqiq41V168DrVVW/PX393qp68fxLZV4OH07270+e8YzJx8OH1+d469y3ZRwPAHazPVs1qKoLkrw3ySuTnEhyT1Ud6e77Z5pdl+SK6Z9rkrx/+pEd5vDh5ODB5PHHJ9tf+9pkO0luumm1j7fOfVvG8QBgt6vuPnuDqp9M8u+6+1XT7bcnSXf/+5k2v5PkU939oen2A0mu7e5vnOnrbmxs9NGjR59+Dzgn+/dPAtZmz3te8tWvrvbx1rlvyzgeZ1dVx7p7Y9l1LIpzNrDKzvecPebWi4uTPDyzfWK671zbpKoOVtXRqjp68uTJc62VOXjooXPbv0rHW+e+LeN4ALDbjQnKNbBv8zD0mDbp7kPdvdHdG/v27RtTH3N22WXntn+VjrfOfVvG8QBgtxsTlE8kuXRm+5Ikj5xHG3aAd70r2bv3yfv27p3sX/XjrXPflnE8ANjtxgTle5JcUVWXV9WFSW5IcmRTmyNJXj99+sXLk/z12e5PZnluuik5dGhyX2vV5OOhQ9s3GWyRx1vnvi3jeACw2205mS9JqurVSd6T5IIkd3T3u6rq5iTp7turqpLcluRAkseTvLG7zzrrw8QQYJWZzAewOs73nL3l4+GSpLvvTnL3pn23z3zeSd58rgcHAICdysp8AAAwQFAGWDNWUwWYD0EZYI3MrKZ6XZKrktxYVVdtaja7murBTFZTBWATQRlgvbwsyfHufrC7n0hyV5LrN7W5PskHe+KzSZ5VVT+y6EIBdrpRk/m2w7Fjxx6rqoEFebd0UZLH5l3PDrHOfUvWu3/6trrOt3/Pm3chczK0Uuo1I9pcnORJj/WsqoOZjDgnyf+pqi/Ot9Qdb91/9ofo8+6wG/v8gvP5S0sLyt19XkvzVdXRdX0k0zr3LVnv/unb6lrD/s11NdUkh5K1/Hfakj7vDvq8O1TVeT3f0q0XAOvFaqoAcyIoA6wXq6kCzMnSbr14Gg4tu4BttM59S9a7f/q2utaqf919qqrekuQT+f+rqd43u5pqJgtIvTrJ8UxXUx3xpdfq32kkfd4d9Hl3OK8+j1rCGgAAdhu3XgAAwABBGQAABqxUUK6qC6rqL6rqY8uuZd6q6llV9eGq+h9V9aWq+sll1zQvVfWvq+q+qvpiVX2oqv7msmt6Oqrqjqp6dPaZslX1t6vqk1X1P6cfn73MGs/XGfr27unP5b1V9d+q6lnLrPF8DfVt5rV/U1VdVRcto7adZDcufz2izzdN+3pvVX2mqq5eRp3ztFWfZ9q9tKq+U1WvXWR922FMn6vq2qr63PR31p8uusZ5G/Gz/UNV9YdV9flpn8fMV9ixznaen75+zuevlQrKSd6W5EvLLmKb/KckH+/uK5NcnTXpZ1VdnORfJdno7hdmMrnohuVW9bTdmeTApn23JvmT7r4iyZ9Mt1fRnXlq3z6Z5IXd/aIkX07y9kUXNSd35ql9S1VdmuSVSR5adEE7zW5c/npkn7+S5Ken74F3ZsUnQo3s8+l2v5HJxNCVNqbP00GA9yV5TXf/eJJfXHihczTy+/zmJPd399VJrk3ym9On5ayqOzNwnp9xzuevlQnKVXVJkp9L8oFl1zJvVfWDSf5Rkt9Nku5+orv/93Krmqs9Sf5WVe1Jsjcr/rzW7v50km9u2n19kt+bfv57Sf7ZQouak6G+dfcfd/ep6eZnM3nm7so5w/ctSX4ryb/NwIIbu9BuXP56yz5392e6+1vTzZV9D8wY831Okrcm+f0kjy6yuG0yps+vS/KR7n4oSbp71fs9ps+d5AeqqpJ8fybnyFNZUWc5z592zuevlQnKSd6TyS+z7y67kG3wd5OcTPKfp7eWfKCqnrnsouahu7+e5D9mMlr3jUye1/rHy61qWzz39HNopx+fs+R6tsu/TPJHyy5iXqrqNUm+3t2fX3YtO8SZlrY+1zar5Fz786as/ntgyz5Prwb+QpLbF1jXdhrzfX5+kmdX1aeq6lhVvX5h1W2PMX2+LcmPZTKA9YUkb+vudcxZp53z+WslgnJV/XySR7v72LJr2SZ7krw4yfu7++8n+XZW99L9k0zv1b0+yeVJfjTJM6vqny+3Ks5HVf1qJiMNh5ddyzxU1d4kv5rkHcuuZQeZ2/LXK2R0f6rqZzIJyrdsa0Xbb0yf35Pklu7+zgLqWYQxfd6T5CWZXL1+VZJfq6rnb3dh22hMn1+V5HOZ/H7+iSS3Ta9yr6tzPn+tRFBO8g+TvKaqvprJpYOfrar/styS5upEkhPd/WfT7Q9nEpzXwT9O8pXuPtnd/zfJR5L8gyXXtB3+8vTlm+nHVb9k9yRV9YYkP5/kpl6fh6//vUz+A/f56bnlkiR/XlV/Z6lVLdduXP56VH+q6kWZ3Pp3fXf/1YJq2y5j+ryR5K7pe+O1Sd5XVSt5S9nU2J/tj3f3t7v7sSSfzmTO0Koa0+c3ZnK7SXf38Uzux79yQfUtwzmfv1YiKHf327v7ku7en8lEsP/e3WszKtnd/yvJw1X1gumuVyS5f4klzdNDSV5eVXun90C9ImsyUXGTI0neMP38DUk+usRa5qqqDmQygvaa7n582fXMS3d/obuf0937p+eWE0lePH0/7la7cfnrLftcVZdl8p/8X+ruLy+hxnnbss/dffnMe+PDSX6lu/9g8aXOzZif7Y8m+amq2jO94nRNVvv31Zg+P5TJ7+VU1XOTvCDJgwutcrHO+fy1iktYr6u3Jjk8/WF+MOOWlN3xuvvPqurDSf48k8v2f5HVnzH+oUxmB19UVSeS/HqS/5Dkv1bVmzI58azkbOkz9O3tSf5Gkk9O/q+Tz3b3zUsr8jwN9a27f3e5Ve0s27j89Y41ss/vSPLDmYyqJsmp7t5YVs1P18g+r5Uxfe7uL1XVx5Pcm8l8qA909+BjxlbByO/zO5PcWVVfyOS2hFumo+kr6Qy/w74vOf/zlyWsAQBgwErcegEAAIsmKAMAwABBGQAABgjKAAAwQFAGAIABgjIAAAwQlAEAYMD/A+VKZTIhwselAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate Dataset\n",
    "reg1 = sklearn.linear_model.LogisticRegression()\n",
    "reg1.fit(x, y1)\n",
    "reg2 = sklearn.linear_model.LogisticRegression()\n",
    "reg2.fit(x, y2)\n",
    "\n",
    "# Plot\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(x, y1, 'bo'); axes[0].plot(sorted_x, reg1.predict_proba(x)[:,1], 'b-');\n",
    "axes[1].plot(x, y2, 'go'); axes[1].plot(sorted_x, reg2.predict_proba(x)[:,1], 'g-'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Dataset\n",
    "reg3 = sklearn.linear_model.LogisticRegression()\n",
    "reg3.fit(x, y3)\n",
    "reg4 = sklearn.linear_model.LogisticRegression()\n",
    "reg4.fit(x4, y4)\n",
    "\n",
    "# Plot\n",
    "sorted_x4 = np.sort(x4.flatten()).reshape(-1, 1)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(x, y3, 'ro'); axes[0].plot(sorted_x, reg3.predict_proba(x)[:,1], 'r-');\n",
    "axes[1].plot(x4, y4, 'ko'); axes[1].plot(sorted_x, reg4.predict_proba(sorted_x4)[:,1], 'k-'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg3.coef_.flatten()) #B1 in the slides\n",
    "print(reg3.intercept_) #B0 in the slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "acc = sklearn.metrics.accuracy_score\n",
    "\n",
    "y1_pred = reg1.predict(x)\n",
    "y2_pred = reg2.predict(x)\n",
    "y3_pred = reg3.predict(x)\n",
    "y4_pred = reg4.predict(x4)\n",
    "acc(y1_pred, y1), acc(y2_pred, y2), acc(y3_pred, y3), acc(y4_pred, y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = sklearn.metrics.f1_score\n",
    "\n",
    "\n",
    "f1(y1_pred, y1), f1(y2_pred, y2), f1(y3_pred, y3), f1(y4_pred, y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "roc = metrics.roc_curve\n",
    "auc = metrics.auc\n",
    "y1_prob=reg1.predict_proba(x)[:,1]\n",
    "y2_prob=reg2.predict_proba(x)[:,1]\n",
    "y3_prob=reg3.predict_proba(x)[:,1]\n",
    "y4_prob=reg4.predict_proba(x)[:,1]\n",
    "\n",
    "fpr1, tpr1, thresholds1 = metrics.roc_curve(y1, y1_prob, pos_label=1)\n",
    "fpr2, tpr2, thresholds2 = metrics.roc_curve(y2, y2_prob, pos_label=1)\n",
    "fpr3, tpr3, thresholds3 = metrics.roc_curve(y3, y3_prob, pos_label=1)\n",
    "fpr4, tpr4, thresholds3 = metrics.roc_curve(y4, y4_prob, pos_label=1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "plt.plot([0,1],[0,1],'k--',label='random')\n",
    "plt.plot(fpr1, tpr1,'b-',label='data1')\n",
    "plt.plot(fpr2, tpr2,'g-',label='data2')\n",
    "plt.plot(fpr3, tpr3,'r-',label='data3')\n",
    "plt.plot(fpr4, tpr4,'k-',label='data4')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "ax.set_aspect('equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print('data1 ROC-AUC: ',auc(fpr1, tpr1))\n",
    "print('data2 ROC-AUC: ',auc(fpr2, tpr2))\n",
    "print('data3 ROC-AUC: ',auc(fpr3, tpr3))\n",
    "print('data4 ROC-AUC: ',auc(fpr4, tpr4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Numeric Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "\n",
    "figure = plt.figure(figsize=(35, 9))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='k')\n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "               edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        scores = [acc(y_pred,y_test),f1(y_pred,y_test)]\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "        # Plot the testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   edgecolors='k', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('Acc:%.2f' % scores[0]).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        ax.text(xx.min()+1.4, yy.min() + .3, ('F1:%.2f' % scores[1]).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        #ax.text(xx.min(), yy.min() + .3, ('%.2f' % scores[2]).lstrip('0'),\n",
    "        #        size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also develop our own data and examples!\n",
    "# Questions to think about\n",
    "# - Are models robust (for new data, will performance be similar?)\n",
    "# - What model performs best?\n",
    "#    - F1, Accuracy, AUC\n",
    "#    - What models are expected to work well on a variety of data?\n",
    "#    - When will models break down?\n",
    "# - What data is noisy? \n",
    "# - What is the best metric?\n",
    "#    - What is your definition of best?\n",
    "#    - E.g., robust (dependence on data)\n",
    "#    - Are high values always reflective of a good model?\n",
    "#    - When does each metric break down?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "rise": {
   "autolaunch": false,
   "enable_chalkboard": true,
   "footer": "",
   "header": "<h3>PHYS 304 | Lecture 01</h3>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
